Overview: The current trace-the-path CAPTCHA can be easily defeated by bots due to an overly informative “peek” endpoint and minimal enforcement of human-like behavior. Below we detail the key weaknesses and propose concrete improvements to harden the CAPTCHA’s security. Our focus is on server-side measures (FastAPI backend) that raise the bar for automation while keeping the puzzle intuitive for legitimate users. We draw on moving target defense principles and research on behavioral bot detection to ensure the solution increases attacker cost and reduces automated success rates.

Identified Weaknesses in the Current Design

Oracle-Like Feedback (/captcha/line/peek): The peek endpoint reveals future path segments on demand, acting as an oracle. A bot can abuse this to retrieve the entire hidden path quickly, then auto-trace it perfectly. This completely bypasses the intended challenge by giving away the “answer.” In summary, too much information is exposed via the API, enabling bots to script a 100% solve rate.

No Sequence or Continuity Enforcement: The CAPTCHA only checks if the path was covered and the end reached. It does not enforce monotonic progress (following the path in order) or continuous movement. A bot can, for example, skip around or even draw segments out of order yet still cover all areas and hit the end, passing validation. A human, by contrast, would naturally trace sequentially. This lack of order enforcement is a glaring loophole.

Ignored Behavioral Signals: Although the system logs behavioral data (e.g. constant speed, lack of jitter in cursor movement), these signals are not used to gate success. Currently a script with unnaturally steady, fast movement passes as long as it covers the path. Human users inherently have variation in speed and pointer micro-movements, whereas bots often produce eerily smooth trajectories. By not acting on these differences, the CAPTCHA misses a critical bot indicator.

Short but Insufficient TTL: Each challenge expires after ~6 seconds, intended to limit bot attempts. However, 6 seconds is more than enough for a scripted bot to complete the trace (especially since it can query the full path instantly). Legitimate users might take ~4–6 seconds anyway, so the current TTL doesn’t truly hinder bots. In effect, the TTL is too lenient given how fast the bot operates. Simply tightening it without other changes could hurt humans, so TTL alone isn’t solving the problem.

Lack of Variation / Moving Target Defense: Aside from the random path itself, the challenge is served in a consistent manner (same endpoint, same behavior each time). This predictability makes it easier for attackers to write a stable bot. There are reusable signals (like the peek responses format, path data structure, etc.) that the attacker can reliably parse each time. The system doesn’t currently employ moving target defense tactics such as dynamic challenge generation or protocol randomization to throw off bots.

Hardening Strategies for the Trace-The-Path CAPTCHA

To address the above issues, we recommend a multi-layered approach that combines limiting feedback, strict server-side validations, and behavioral analysis. These measures, implemented on the FastAPI backend and integrated with the canvas frontend, will significantly increase the difficulty for bots while preserving a smooth user experience for humans.

1. Restrict and Throttle the “Peek” Feedback Channel

Limit Lookahead: Reduce the oracle nature of the peek endpoint by only revealing the immediate next segment (or a very small window) of the path. Currently, a bot can repeatedly call /peek and stitch together the entire route. Instead, design /peek to respond only when the user’s cursor is near the edge of the already-revealed path (or start point) and return just the next incremental segment. This ensures the user can see where to go only step-by-step, preventing a bot from dumping the full solution. It also enforces a monotonic revelation: the path is uncovered sequentially. If a bot tries to jump ahead out of order, the server should simply refuse to provide distant segments.

Server-Side State Check: Maintain on the server a state of how far along the path the user has progressed. For example, keep an index or reference to the last revealed segment. On each /peek request, verify that the request is proximate to that frontier. If a request asks for a segment that is not adjacent to what’s already uncovered (i.e. non-monotonic or skipping ahead), treat it as suspicious – the server can return no data or an error. A legitimate user’s cursor wouldn’t be able to magically skip forward without following the path, so this won’t hinder real users. But it will stop bots from arbitrarily querying segments out of sequence.

Rate Limiting and Throttling: Add a strict rate-limit to how often the client can call /peek. A human tracing a line moves at a limited speed – perhaps a few dozen pixels per second – so they might trigger, say, 5–10 peek calls per second at most. You can enforce a cap (e.g. no more than 10 calls per second) or introduce a tiny delay (50–100 ms) before responding with the next segment. This will be nearly unnoticeable to users (who aren’t moving or perceiving updates that fast), but it drastically slows down a bot that tries to spam the endpoint or scan the whole canvas. In FastAPI, this can be done by tracking timestamps of last calls per session/IP and returning a 429 or intentionally sleeping if calls come too fast. By throttling the reveal rate, you ensure a bot can’t gather the path significantly faster than a human would through normal play.

Feedback Randomization (Noisy Lookahead): As an optional enhancement, consider introducing minor noise or ambiguity in the peek feedback beyond the immediate next step. For instance, the endpoint could reveal the next segment plus a “hint” of one additional segment that is slightly randomized or obscured. The human user, who is following incrementally, will only rely on the immediate clear segment; the extra hint might give them a general sense of direction but not enough to trace blindly. A bot, on the other hand, might attempt to use that extra data to map out the path and could be misled by the noise. This idea must be used carefully (so as not to confuse users), but it can reduce the oracle precision. The key is that the CAPTCHA should not act as a perfect future-seeing oracle – any lookahead given should be just sufficient for human guidance but not so exact that a bot can fully exploit it.

Result: By tightening the peek mechanism, we eliminate the easy “tell me everything” exploit. The bot is forced to follow the path stepwise just like a human. Combined with rate limits, this means the automated solver can no longer complete the task orders of magnitude faster than a person. It must invest time and cannot skip ahead, greatly raising its complexity. These changes implement the moving target defense ethos of reducing oracle signals and preventing the bot from gaining reusable knowledge of the solution in one go.

2. Enforce Monotonic Path-Following and Continuity

Sequential Segment Enforcement: On the server’s validation step (when the user claims to have solved the CAPTCHA), check that the path was drawn in order from start to finish. Since you know the intended path sequence, you can verify that segment 1 was covered before segment 2, segment 2 before 3, and so on. If any segment is marked as “covered” timestamp-wise earlier than a previous segment (or if any expected segment was skipped and then covered later), that indicates out-of-order tracing. This should result in a failure or at least a very high suspicion flag. In practice, a human tracer will satisfy monotonic coverage because they physically move along the line. A bot that tried to shortcut by jumping around would violate this, and now such attempts can be caught and rejected server-side.

Single Continuous Stroke: Require that the trace is one continuous motion from start to end. If the design expects the user to click and hold (or continuously touch) while tracing, then any lifting of the mouse/touch (or a significant break in the stream of pointer events) could invalidate the attempt. A human isn’t likely to release the mouse in the middle of tracing the line (and if they do accidentally, one might consider failing that attempt or giving a retry). Ensuring a continuous drag adds security: a bot that attempted to draw disjoint segments or use multiple “cursors” concurrently would not meet this criterion. The server can enforce this by recording the time of start and end of the gesture and ensuring that intermediate points were received throughout. If the front-end only sends segments via peek, you might instrument it such that the first peek marks the “mouse-down start” and reaching the end or timeout marks “mouse-up.” If any gap or multi-stroke pattern is detected, invalidate the attempt.

No Teleportation (Physical Plausibility): Human users have to move through every intermediate point along the path — they cannot teleport the cursor from one part of the path to a distant part instantly without traveling the pixels in between. Bots, however, might try to “teleport” the pointer in a script (especially if not simulating events at a fine granularity). On the server, you can perform a simple distance/time check between consecutive peek calls or pointer positions: if the jump is too large to have been done by a real user in the elapsed time, you know the movement was non-human. For example, if between two peek calls the cursor coordinates moved say 300 pixels in 5 milliseconds, that’s impossible for a real mouse (that implies an absurd speed or a discontinuity). This is a sign of a bot trying to skip or move instantly. The server can flag this and fail the challenge. Essentially, you’re enforcing that movement follows a continuous path with bounded speed (more on speed limits below). This check ensures the trajectory is physically realistic for a human arm/hand.

Monotonic Lookahead on Server: As mentioned earlier, implement the server logic so that it only provides new path info if the user is at the current frontier. This not only limits info but also implicitly forces the user’s drawn path to be contiguous. If a bot tried to circumvent this by, say, spawning multiple threads that each start at the beginning and trace different branches (if the path had branches), the server’s monotonic gating would prevent any branch that isn’t contiguous from being revealed. In short, monotonic server logic == user must actually trace.

Result: These measures close the loophole of out-of-order drawing. The CAPTCHA now truly demands “trace the path” in the correct sequence. A bot can no longer, for instance, draw the end first and then the middle; it has to actually simulate a continuous follow. This aligns the technical enforcement with the intuitive task we expect the user to do. It doesn’t make the task any harder for humans (who will naturally do it in order), but it will cause any non-human approach that deviates from a normal tracing order to fail validation.

3. Validate Human-Like Trajectory Behavior

Even if a bot is forced to trace sequentially, it may try to do so in a perfectly machine-like manner. The next layer of defense is to analyze the dynamics of the tracing and look for telltale signs of automation. Research consistently shows that human mouse movements have distinct neuromotor patterns that bots struggle to replicate. By incorporating behavioral checks on the server side, we can dramatically boost security with minimal impact on user experience:

Comparison of a real human mouse trajectory (A, orange curve) versus synthetic bot-like trajectories (B–F) and their velocity profiles. The human exhibits an initial acceleration phase and fine trajectory adjustments (minor jitters), whereas bot-generated traces are often overly smooth or maintain nearly constant speed (e.g. profile E shows an unnaturally flat velocity).

Speed Variance and Jitter: Humans do not move a mouse at perfectly constant speed – there are natural fluctuations in velocity and small hand jitter. Bots frequently produce a steady, linear movement with little to no jitter. The server should calculate the pointer speed profile along the path and its variance. If the velocity is almost constant (low standard deviation) or if the path looks unnaturally smooth (e.g. no tiny zig-zags at the pixel level), that’s a red flag. For example, a human might slow down slightly to round a curve or speed up on a straight, and their hand will shake by a few pixels. A bot given the exact path might move with uniform, robotic precision. We can quantify this by features like speed variance, frequency of direction changes, or even spectral analysis of the movement noise. In practice, a simpler rule could be: require at least some minimal amount of cursor movement entropy (small random-looking deviations) over a path length. If a trace is too perfect, it likely isn’t human.

Acceleration/Deceleration Patterns: Human motions typically have a quick start and a slow finish (following a roughly lognormal velocity profile as per Fitts' law in human motor behavior). In other words, when a user begins tracing, they accelerate, and as they approach the end or need to stop, they decelerate. Bots that script cursor movements might not emulate this; they may move each segment at a uniform pace or even do abrupt stops. The server can check if the movement had a single peak speed and then tailed off near the end, which is expected of human neuromotor behavior. No deceleration at the end (the cursor stops abruptly with no slowdown) could indicate a scripted motion. Similarly, if the user’s initial movement from the start was extremely slow (a bot carefully plotting) or perfectly instantaneous to max speed, it might be suspect. In summary, look for a natural acceleration curve followed by a braking phase. This can be done by examining the timestamped positions from the start to end of the trace.

Hesitation and Corrections: Humans often make fine trajectory adjustments – e.g., slight course corrections if they drift off the line, or momentary hesitations at tricky spots (like a sharp turn). A bot following a precomputed path will likely draw a mathematically precise curve with no pauses or corrections. You can monitor the timing between events: if the cursor movement has absolutely uniform time gaps and never pauses, it’s fishy. Likewise, if there are zero minor backtracks or angle changes where the path might be difficult, that’s suspect. In contrast, a human might overshoot a curve and correct by moving back a couple of pixels (which would appear as a quick reversal in direction locally). Implementing a full analysis of angle trajectories might be complex, but even a simple metric like “number of direction changes” or “total curvature” compared to an ideal path could help. If a user’s path exactly matches the ideal path shape with no deviation, it could mean the path was known (a bot). Some deviation is natural and should be expected from genuine users.

Impossible Speed and Timing: Set thresholds for maximum humanly possible speed. For example, if the user moved the cursor across the entire path in 0.5 seconds, that’s almost certainly a bot (or a superhuman flick). You can use data about typical mouse speeds; even a very skilled user has a limit to how fast they can accurately trace a line. If the path length is known (say X pixels), you can set a minimum completion time T_min that is physically plausible. If the solve time is < T_min, auto-fail that attempt as bot. (In practice, you might allow a small buffer for unusually skilled users, but you’d be surprised how consistent human reaction times are – nobody can trace a complex curve in, say, under 1 second). Additionally, you can watch for time gaps that are too small between successive points. If your front-end sends continuous coordinates or if the peek calls are coming in at microsecond intervals, clearly it’s automated. A genuine user’s device will send events at, for example, 16ms intervals (60 Hz) or similar; events timestamped 1ms apart are not from a real mouse. Ensuring the timestamps between movements aren’t unrealistically low is another check.

Pattern Recognition (Advanced): If resources allow, you could integrate a learning-based classifier trained on human vs. bot traces. For instance, the BeCAPTCHA-Mouse system uses a neuromotor model and has shown 93% accuracy in distinguishing human mouse trajectories from bot-generated ones. Features can include those mentioned (speed, jitter, curvature) and more complex ones. Training such a model would require collecting some data, but even without ML, the above heuristic rules catch the obvious discrepancies. Academic studies confirm that using these behavioral features can reliably detect bots even when they try to spoof human-like movements. The key takeaway is to use the rich data from the user’s drawing action, not just treat it as a static result.

Implementation (FastAPI): To achieve this, ensure the backend collects the necessary data. For example, when the user is tracing, the front-end could periodically send the pointer coordinates and timestamps (this could be piggybacked on the peek requests or sent in a batch at the end). The FastAPI server can accumulate the sequence of points the user moved along. At validation time (when the user says they’re done or reached the end), run the collected trajectory through the checks above. This might involve calculating average vs. max speed, computing variance, etc. If any check fails (or if a combined “bot likelihood score” exceeds a threshold), the server rejects the attempt even if coverage and order were correct. This ensures truly automated behavior gets flagged even if it technically traced the line.

From the user’s perspective, these checks are invisible – a genuine user will naturally satisfy them (e.g. they will have some jitter, they will take a reasonable amount of time, etc.). Thus, there is no added burden on the user; you’re simply leveraging their inherent human imperfections as proof of humanity. Bots, however, must now either greatly slow down and mimic human noise (hard to do well) or be caught. Indeed, requiring bots to introduce human-like variability significantly raises their cost: it may require machine learning to generate realistic trajectories or risk making mistakes. Even state-of-the-art generative bots struggle to perfectly emulate human neuromotor patterns. This layered behavioral defense aligns with recommendations in recent security literature, which emphasize that “simulation-resistant trajectories” (those requiring human-like velocity, acceleration, and jitter) make automated attacks much more difficult.

4. Impose Realistic Timing and Sequence Constraints

This is partly covered by earlier points, but to summarize and add a few extra tactics:

Minimum and Maximum Solve Time: Set a minimum duration that the tracing should take (to catch overly fast solves) and possibly a maximum (to expire stuck bots, though your TTL already covers that). For example, if a user finished in under, say, 2 seconds and the path length was non-trivial, that’s a fail. Conversely, if someone takes too long (e.g. over 10–15 seconds) you might consider it timed out (though 6s TTL already handles that – you might consider slightly extending TTL if your other checks are strong, to avoid penalizing meticulous humans, but you’d rely on behavioral checks to catch bots who try to slow-play). The main idea is that normal human tracing has a realistic speed range – enforce that range. In FastAPI, you know when the challenge was served and when it was completed; use that difference as the solve time.

One Path, One Try: Ensure that if the user fails or deviates too much, you invalidate and possibly regenerate a new random path (moving target). Don’t allow the same path to be reused, as a bot could learn from a failed attempt (this falls under “no reusable signals”). The short TTL and generation of a new challenge on retry achieves this. Essentially, every attempt should be fresh and independent, so a bot can’t incrementally solve by trial and error.

Monotonic Input Enforcement on Client: While we prefer server-side enforcement (since client-side can be tampered with), adding some front-end constraints can further guide users and slightly hinder naive bots. For instance, the front-end JS can refuse to call /peek if the cursor is nowhere near the current revealed end of the path. It can also stop the user from starting anywhere except the known start point. This way, even if a bot controller tries to script the front-end, they would have to simulate a fairly realistic use of the UI (which a headless browser bot might do, but a simple HTTP script would not). Any client-side checks should be mirrored or at least double-checked server-side (never trust them blindly), but they can serve as an extra hurdle and also improve user experience (preventing accidental misuse).

Covering the Path Orderly: The server can also enforce that no segment is left uncovered. While coverage is already checked, you might require that at no point should the user skip over a segment without activating it. In practice, if using monotonic peek, this is ensured. But consider if the path has a branching or multiple routes (likely it doesn’t in your design – presumably one continuous path). If it did, you’d want to ensure the user didn’t magically switch branches. This ties into monotonic path enforcement and is likely not needed if the path is single and linear.

Result: By capping min/max times and making each attempt unique, we address edge cases like a bot trying to brute-force in multiple runs or an extremely slow bot attempting to “fly under the radar.” The challenge becomes a one-shot, constrained-time task in a Goldilocks zone of difficulty: humans have ample time to solve, but bots can neither blitz through at machine speed nor stall indefinitely to carefully compute a solution.

5. Increase Challenge Variability (Moving Target Defense)

To prevent attackers from adapting too easily, apply Moving Target Defense (MTD) principles to the CAPTCHA’s implementation. This means regularly changing aspects of the challenge and environment so that even if a bot is adapted to one version, it won’t work on the next. Here are specific MTD tactics:

Dynamic Path Generation: Continue to generate the path procedurally each time (with enough randomness that patterns can’t be learned). You might also randomize the path’s complexity or shape slightly per session. For example, vary the number of turns or the general layout (sometimes a winding curve, other times a zigzag). If the difficulty needs to remain consistent, keep it within a range, but avoid using a small set of preset paths that could be memorized. Ensure no two challenges are identical or predictable. This procedural variation means a bot can’t train specifically on one shape or rely on image recognition of a known pattern.

Distractor Elements (if applicable): Some implementations of line-tracing CAPTCHAs (e.g., LineCAPTCHA research) add distractor lines or noise in the image. Since your design is based on invisible paths revealed by interaction, the equivalent could be to occasionally show extra irrelevant strokes when the user strays far off the path, or to have multiple faint lines initially but only one responds to tracing. However, this might complicate the UX (you’d have to hint which one is correct somehow). Use distractors cautiously on the front-end if at all. The goal is to confuse bots that try to do image processing or random guessing, while a human would intuitively follow only the interactive feedback from the correct path. In a dynamic setting, one idea is: if the user’s cursor moves in an area with no path, you do not reveal anything (or you could even briefly flash a fake segment to throw off bots – but that could confuse humans, so it’s not generally recommended). The safer approach is to simply not assist the user when they are “cold” (not near the path), whereas a bot scanning pixel by pixel might spend time in cold areas and gain nothing.

Obfuscate the API and Front-End Code: Consider making the bot’s job harder by not having a plainly documented, unchanging endpoint. For instance, the path peek endpoint could include a session-specific token or a changing URL (like /captcha/line/peek/<random-id>). You can embed this random endpoint or a required CSRF token in the page when serving the CAPTCHA. A legitimate browser will use it, but a generic bot script might not know how to handle the randomized endpoint name or token. Furthermore, you could periodically change the parameter names or JSON structure returned by /peek. This is a form of polymorphism – essentially, don’t let the attacker hard-code a solution. If they reverse-engineer it today, rotate some keys tomorrow. This aligns with using ephemeral, non-reusable signals. In fact, researchers have proposed polymorphic web code generation to thwart bots: dynamically rewriting or obfuscating parts of the page so that automated scripts have to constantly adapt. In FastAPI, this could be as simple as including a random challenge ID and requiring it in the peek request (and verifying server-side), or as advanced as serving a small piece of JavaScript that computes something the server will check (proof-of-work or encryption of coordinates, etc., to ensure the request came from the genuine client code). Even adding junk parameters or randomizing the order of JSON fields can trip up brittle bot scripts.

Short-lived Tokens: Your use of TTL is good – ensure that any token or session ID associated with the CAPTCHA is invalidated after the time-out or after one use. If a bot somehow obtains a path (e.g. via the peek), that information should expire immediately after the attempt. Also, tie the solved result to a specific session so it can’t be reused elsewhere. Essentially, one challenge, one solve. If the bot tries to reuse a solution or data beyond its validity, it should fail. This prevents replay attacks and sharing of answers (not that a static answer works here, but just in principle).

Leverage Passive Signals (if available): Since you have a canvas front-end, you could also incorporate some passive bot detection signals similar to reCAPTCHA v3’s approach. For example, monitor how the user’s cursor moved before even starting the trace: did they move at all, or did they jump straight to the start pixel? Humans might jiggle the mouse or take a moment, whereas a bot could go instantly to coordinate (x_start, y_start) with zero delay. You can record the initial delay from challenge render to first action. If it’s essentially zero or always the same, that’s suspect. Other signals: is the user’s pointer focus in the canvas or did it come from off-screen (bots might programmatically focus the canvas element)? Are there any other events like key presses or context menu opens (maybe not relevant here)? These ancillary behaviors can add to a bot score. Google’s reCAPTCHA v3 examines tons of such signals (browser properties, history of user, etc.) to assign a risk score. While you need not go to that extent, adding a bit of passive analysis can further strengthen your CAPTCHA. For instance, if your CAPTCHA is embedded in a page, you could use a small script to detect if the user had any interaction before clicking “Start trace” (like scroll or mouse movement on the page) – real users often do, bots might not. However, use these as supplemental signals, not primary (to avoid false positives against careful users or accessibility tools).

Result: Embracing MTD means the bot cannot rely on a single method or knowledge for long. Even if it manages to solve one aspect (say it manages to simulate some jitter to pass the behavioral check), it might still fail if the next day you deploy a slight change in the challenge format or path generation. The attacker is forced into a constant game of catch-up, ideally to the point where it’s not worth the effort. Meanwhile, legitimate users mostly see a consistent puzzle (trace the line) — the variations are under the hood or subtle enough that they don’t reduce usability. Studies on CAPTCHA security note that dynamic and procedural variations greatly improve robustness, while keeping human success high. By balancing these, we ensure the CAPTCHA stays ahead of automated attacks without frustrating users.

Recommendations Summary (FastAPI + Canvas Integration)

Bringing it all together, here’s a concrete plan of action tailored to your FastAPI backend and canvas frontend:

Secure the Peek Endpoint: Modify /captcha/line/peek to require a valid session token and to only reveal the next path segment if the query point is near the last revealed segment. Implement server-side checks for proximity and sequence. Deny or ignore out-of-sequence requests. Apply rate limiting (e.g. via an in-memory counter or FastAPI dependency) to slow down rapid calls. This prevents the endpoint from being a path oracle for bots.

Server-Side Path State: Keep track of the user’s progress on the server (e.g., index of last segment revealed, timestamps of reveals). This state can be stored in a cache or dict keyed by session ID. Use it to validate both peek requests and the final solve. For final validation, ensure all segments were revealed in order and within reasonable time.

Collect Movement Data: Instrument the front-end (JavaScript) to send pointer movement data. For example, on each mousemove or at least on each peek, send the current coordinates and perhaps a movement delta. Alternatively, record the entire path client-side and submit it at the end. Make sure this data is tied to the server’s notion of session to prevent tampering. (You could sign it or simply trust it in the context of the active session, since a bot could fake data but then it would have to fake good human-like data, which is hard.) This gives the server the raw info needed for behavioral checks.

Implement Behavioral Checks: In the FastAPI validation logic, analyze the collected trajectory:

Compute total time, average speed, max speed.

Compute speed variance or detect if speeds are all equal.

Check for any large sudden jumps.

Look for small oscillations or lack thereof.

If available, examine the velocity profile (you might approximate this by looking at distance per time slice).

Set thresholds (e.g., > certain speed = fail, < certain variability = fail, etc.) based on reasonable human data. You might calibrate these by testing with a few humans if possible.

If a trajectory fails these checks, do not accept the solve. You can either outright reject (forcing the challenge to be attempted anew) or present an additional verification step if you want to be safe (for example, “We detected unusual tracing behavior, please try again” – this hints the user might have been a bot, but an actual user might rarely see this if thresholds are well-chosen).

Adjust TTL and Difficulty if Needed: With the above measures in place, you might experiment with the TTL. If bots are significantly slowed by rate limits and checks, a 6-second TTL might actually become harsh for humans (if they take close to that to solve). Consider slightly extending TTL to, say, 8–10 seconds to ensure most users can finish, since the primary anti-bot mechanisms are now elsewhere. The TTL then mainly handles denial-of-service scenarios (too many open challenges) rather than stopping a fast bot (the bot can’t be fast now anyway). Also ensure the challenge regeneration logic on timeout is solid (issue a new random path and invalidate the old one and its token).

Logging and Iteration: Add logging on the server for invalid attempts – log why an attempt failed (e.g., “speed too high” or “out of sequence”). Over time, analyze these logs. If you find no legitimate users are tripping the checks, you can tighten them further. If some legitimate users do fail (false positives), you might relax a threshold or implement a softer fail (maybe allow one retry with a warning). The goal is to continuously tune the system for maximum security without locking out real users. User experience testing is important: ensure the path is neither too easy for bots nor too hard for humans to complete in time. The user-friendliness should remain high, which research suggests is achievable – users generally prefer a quick drawing task over deciphering distorted text. High completion rates and preference scores have been reported for line-drawing CAPTCHAs on touch devices, so with these defenses, we aim to keep it that way.

Stay Unpredictable: Periodically (and seamlessly) update aspects of the challenge. For example, if you suspect bots started to mimic one aspect (say they now add a bit of jitter), you could increase the required jitter level or add another feature check. Since you have the flexibility of a custom CAPTCHA, feel free to iterate on the design. Keep an eye on emerging research or known bypass techniques. Incorporating findings from studies like Akrout et al.’s reinforcement learning attack on reCAPTCHA (which taught us that even “invisible” CAPTCHAs can be learned around if static) or new bot detection algorithms will ensure your CAPTCHA stays a moving target.

By following these recommendations, your trace-the-path CAPTCHA will transform from an easy target to a robust challenge. An attacking bot now must simulate a human in many respects: it can no longer simply query an endpoint for the solution, nor zip through the path at machine speed, nor draw with superhuman precision. It would need to obey the sequential reveal protocol, incorporate realistic pauses and noise, and still finish within the time window – essentially, it must pass a kind of behavioral Turing Test embedded in the CAPTCHA. This dramatically raises the development effort and computational cost for the attacker. Meanwhile, human users still experience a quick, interactive puzzle: they move their mouse along a hidden line that gradually appears. If they do so normally, they’ll pass with little friction. These improvements implement both active challenge security (the puzzle itself) and passive behavioral analysis. Such a hybrid approach has been shown in research and practice to yield measurably better bot resistance, without sacrificing usability.

In conclusion, by reducing oracle-like feedback, enforcing proper tracing behavior, leveraging human movement characteristics, and adopting moving target defenses, we make the trace-the-path CAPTCHA significantly more resilient. The goal of increasing attacker cost is achieved: a one-off script will no longer suffice – defeating the CAPTCHA would likely require advanced algorithms or human intervention, which lowers automated success rates drastically. At the same time, genuine users will find the CAPTCHA as convenient as before, if not more (since subtle improvements like slight TTL increase or path guidance won’t harm them). This balanced, defense-in-depth strategy should greatly improve the security of your FastAPI+Canvas CAPTCHA system while maintaining a user-friendly experience.

Sources:

Acien et al., “BeCAPTCHA-Mouse: Synthetic mouse trajectories and improved bot detection,” 2022 – demonstrated 93% accuracy in classifying human vs. bot mouse movements using one trajectory and highlighted human-specific motion features.

Acien et al., “BeCAPTCHA: Behavioral Bot Detection using Touchscreen and Mobile Sensors,” 2020 – introduced behavioral biometrics for CAPTCHAs, emphasizing drag/draw tasks to distinguish bots.

Akrout & Feriani, “Hacking Google reCAPTCHA v3 using Reinforcement Learning,” 2019 – revealed that reCAPTCHA v3’s behavior scoring can be bypassed by trained bot trajectories.

Bulumulla et al., “LineCAPTCHA: A User Friendly Replacement for Unfriendly Tests,” 2014 – proposed a line-drawing CAPTCHA and found users preferred spatial drawing challenges on mobile, with high success rates.

Emergent Mind (Kharlamova et al. 2025), “Spatial CAPTCHA: Methods and Challenges,” – overview of spatial interactive CAPTCHAs; notes that requiring human-like motion (with realistic velocity/jitter) makes automation difficult and that user-centric design must be balanced with security.

ResearchGate figures from BeCAPTCHA-Mouse – illustrate differences between human and bot mouse trajectories and velocity profiles, underscoring why features like jitter and variable speed are effective bot discriminators.

Rizwan Ur Rahman et al., “Polymorphic Code Generation Engine for Web Bot Defense,” 2025 – discusses dynamically altering web content and scripts to confound bots (supports use of ever-changing tokens, obfuscation in the CAPTCHA delivery).

Google reCAPTCHA v3 documentation – describes the move to invisible, behavior-based CAPTCHAs, which, while user-friendly, rely on detecting subtle user behaviors (a concept we apply internally without user impact).
